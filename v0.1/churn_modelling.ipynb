{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20304,
     "status": "ok",
     "timestamp": 1614114133531,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "aNhvS7kPiWDi",
    "outputId": "62328abc-1cae-4c4e-99ec-3b5ce76f3672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZxCVsDEjhp5"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import time\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMC57AXfjoEa"
   },
   "outputs": [],
   "source": [
    "## Folder path\n",
    "folder_path = Path.cwd().joinpath('drive', 'My Drive', 'Colab Notebooks', 'customer_churn_prediction', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 6021,
     "status": "ok",
     "timestamp": 1614114147585,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "_OhJICjUjpbI",
    "outputId": "427832b9-0556-46b5-f955-ced25ec86bfd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YSs/vsH+AL1WRvlkoLDGFT9wWihtQnqQZuKhqdcybm0=</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-22</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>116.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3541.0</td>\n",
       "      <td>2912.0</td>\n",
       "      <td>866766.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WxkFqbfXFSQgzlLld/tgOEFA9oGpf7JmPgsaMryCZWg=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-09-06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6766.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58GesZdrmqPIpKnmdzPnUpw07joB4w8ayPNVfhMPPY4=</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-24</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>127.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>318577.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4LqpGjJ/MUOT3a0WEcSUI6xEykQACYUX0pCPm0xgVsg=</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-02-20</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014-12-04</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>137037.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>limE8R97wWE+cNSl8CXf0CG/wmI4m1WaZQYPxcjz184=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2011-12-17</td>\n",
       "      <td>98.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>125289.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  ...  num_unq  total_secs\n",
       "0  YSs/vsH+AL1WRvlkoLDGFT9wWihtQnqQZuKhqdcybm0=         0  ...   2912.0  866766.109\n",
       "1  WxkFqbfXFSQgzlLld/tgOEFA9oGpf7JmPgsaMryCZWg=         0  ...     33.0    6766.055\n",
       "2  58GesZdrmqPIpKnmdzPnUpw07joB4w8ayPNVfhMPPY4=         0  ...   1060.0  318577.925\n",
       "3  4LqpGjJ/MUOT3a0WEcSUI6xEykQACYUX0pCPm0xgVsg=         1  ...    560.0  137037.344\n",
       "4  limE8R97wWE+cNSl8CXf0CG/wmI4m1WaZQYPxcjz184=         0  ...    399.0  125289.625\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read training and validation data\n",
    "train_val_data = pd.read_csv(folder_path.joinpath('train_val_data.csv'))\n",
    "train_val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 3721,
     "status": "ok",
     "timestamp": 1614114149312,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "pUQwegLRj49i",
    "outputId": "0806fa7f-ff60-4a3a-a138-ba38f080bbb6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/lUtWg8ExxX7WttR/T0UEV5ZmHSjlI+2kEbHdOLQu4o=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>76.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>51682.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZKuhr2ZHSE6jAd25Mv1DC/f7q2oZUV9NpxF//1KAC/E=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>43.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>33348.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kea1xZZjKRAB3aaYIB1BSM580q2pqxxW/dYId7fEcqU=</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012-03-03</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>85705.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IesOUKSq3onwcJe/MXEBAEw0U/8+qhFa4GQPAxm8EAo=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-24</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>163959.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HWAZShjWZK98M68I5CJq03m7Mgiq/vmN53/GkXGi4+E=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>34568.674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  ...  num_unq  total_secs\n",
       "0  /lUtWg8ExxX7WttR/T0UEV5ZmHSjlI+2kEbHdOLQu4o=         0  ...    109.0   51682.863\n",
       "1  ZKuhr2ZHSE6jAd25Mv1DC/f7q2oZUV9NpxF//1KAC/E=         0  ...    180.0   33348.512\n",
       "2  Kea1xZZjKRAB3aaYIB1BSM580q2pqxxW/dYId7fEcqU=         0  ...    356.0   85705.528\n",
       "3  IesOUKSq3onwcJe/MXEBAEw0U/8+qhFa4GQPAxm8EAo=         0  ...    608.0  163959.090\n",
       "4  HWAZShjWZK98M68I5CJq03m7Mgiq/vmN53/GkXGi4+E=         0  ...    132.0   34568.674\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read test data\n",
    "test_data = pd.read_csv(folder_path.joinpath('test_data.csv'))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1614114157943,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "dMesc9ROEPIb",
    "outputId": "67f77f9c-6f7e-4e09-f9ce-e639a4b48266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                       object\n",
       "is_churn                    int64\n",
       "payment_method_id         float64\n",
       "payment_plan_days         float64\n",
       "plan_list_price           float64\n",
       "actual_amount_paid        float64\n",
       "is_auto_renew             float64\n",
       "transaction_date           object\n",
       "membership_expire_date     object\n",
       "is_cancel                 float64\n",
       "city                      float64\n",
       "bd                        float64\n",
       "gender                     object\n",
       "registered_via            float64\n",
       "registration_init_time     object\n",
       "num_25                    float64\n",
       "num_50                    float64\n",
       "num_75                    float64\n",
       "num_985                   float64\n",
       "num_100                   float64\n",
       "num_unq                   float64\n",
       "total_secs                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1614114159939,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "tyiqWAO48LAo",
    "outputId": "da8d49b4-e1a3-482f-a337-50290a71bcbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                       0.00000\n",
       "is_churn                   0.00000\n",
       "payment_method_id          3.85449\n",
       "payment_plan_days          3.85449\n",
       "plan_list_price            3.85449\n",
       "actual_amount_paid         3.85449\n",
       "is_auto_renew              3.85449\n",
       "transaction_date           3.85449\n",
       "membership_expire_date     3.85449\n",
       "is_cancel                  3.85449\n",
       "city                      11.32785\n",
       "bd                        11.32785\n",
       "gender                    59.93507\n",
       "registered_via            11.32785\n",
       "registration_init_time    11.32785\n",
       "num_25                    22.29340\n",
       "num_50                    22.29340\n",
       "num_75                    22.29340\n",
       "num_985                   22.29340\n",
       "num_100                   22.29340\n",
       "num_unq                   22.29340\n",
       "total_secs                22.29340\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Percentage of NA values for each column\n",
    "(train_val_data.isna()).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7AcB4QmRAz5"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gqZaAWiQ56k"
   },
   "source": [
    "### Add a new column for price discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7PdwYU_Q5aY"
   },
   "outputs": [],
   "source": [
    "train_val_data['price_discount'] = train_val_data['plan_list_price'] - train_val_data['actual_amount_paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1614114162528,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "JeN8q9tIRFNb",
    "outputId": "5092e1c1-feb1-45eb-b19c-2d01d0086e71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_val_data['price_discount'] < 0) ## There are 3 datapoints for which price discount is negative. Adjust those impure datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1614114162709,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "wHocIxrERFQe",
    "outputId": "813bf290-abb2-4111-cb58-67c56f0aecd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>price_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259910</th>\n",
       "      <td>NcZX/RK3ZC8tdatMRed2g5T21FoeahEOFp5zfyX2xl0=</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2011-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742078</th>\n",
       "      <td>45UpnCjLzdXmZx6QtGiiylUb6bdaBzwg2UXwukwotrw=</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014-07-12</td>\n",
       "      <td>111.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>116931.92</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758911</th>\n",
       "      <td>IC9SswMka7S1+iCPxMjxb9S/cwR1LWdPotaDhrqKxXo=</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2010-05-13</td>\n",
       "      <td>31.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>116087.23</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                msno  ...  price_discount\n",
       "259910  NcZX/RK3ZC8tdatMRed2g5T21FoeahEOFp5zfyX2xl0=  ...          -149.0\n",
       "742078  45UpnCjLzdXmZx6QtGiiylUb6bdaBzwg2UXwukwotrw=  ...            -1.0\n",
       "758911  IC9SswMka7S1+iCPxMjxb9S/cwR1LWdPotaDhrqKxXo=  ...            -1.0\n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_data.loc[train_val_data['price_discount'] < 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HltQUx5RLJM"
   },
   "outputs": [],
   "source": [
    "train_val_data.loc[[742078,758911], 'plan_list_price'] = 127.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys8iZ2oPROFz"
   },
   "outputs": [],
   "source": [
    "train_val_data.loc[259910, 'plan_list_price'] = 149.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCPL0y2oROJM"
   },
   "outputs": [],
   "source": [
    "## Recompute price discount\n",
    "train_val_data['price_discount'] = train_val_data['plan_list_price'] - train_val_data['actual_amount_paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_n7EqYCpegt"
   },
   "outputs": [],
   "source": [
    "## Split train_val data into train and val data\n",
    "train_df, val_df = train_test_split(train_val_data, test_size=0.15, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1614114167089,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "z_g0mJUnqair",
    "outputId": "98caf729-6f72-4644-86cd-ec22a16389d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>price_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66983</th>\n",
       "      <td>5b20roNDwa3p3z0Y3aWtYMuG0dGRB0tDAIwiYHm38mw=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>367.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>196341.137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242418</th>\n",
       "      <td>O+PqZOEN+6Fq5wr+dpntGdnzaSpnUPUIj3el0IAylYY=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>263.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>194550.134</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455493</th>\n",
       "      <td>lNmJE7vrHFf9/Zp2iGgayiNJMt9Wi17i7EHTBenArIY=</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>female</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013-09-14</td>\n",
       "      <td>690.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>570913.226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866243</th>\n",
       "      <td>Zf62RXGDnyehoy837HpuoOQy9WdJFPiltWqBcZP+2F0=</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-14</td>\n",
       "      <td>2017-04-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92633.412</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83612</th>\n",
       "      <td>rlyej0t+xs1y8MIjClijpXSatK8QOzBI0kok5HO7FtA=</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>2017-04-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2007-10-07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>129521.047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                msno  ...  price_discount\n",
       "66983   5b20roNDwa3p3z0Y3aWtYMuG0dGRB0tDAIwiYHm38mw=  ...             0.0\n",
       "242418  O+PqZOEN+6Fq5wr+dpntGdnzaSpnUPUIj3el0IAylYY=  ...             0.0\n",
       "455493  lNmJE7vrHFf9/Zp2iGgayiNJMt9Wi17i7EHTBenArIY=  ...             0.0\n",
       "866243  Zf62RXGDnyehoy837HpuoOQy9WdJFPiltWqBcZP+2F0=  ...             0.0\n",
       "83612   rlyej0t+xs1y8MIjClijpXSatK8QOzBI0kok5HO7FtA=  ...             0.0\n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0YMG806nIWp"
   },
   "source": [
    "## Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWudEOHR-LUG"
   },
   "outputs": [],
   "source": [
    "## Numeric features imputer\n",
    "numeric_feature_imputer = SimpleImputer(strategy='median')\n",
    "numeric_columns = ['plan_list_price', 'actual_amount_paid', 'bd', 'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs', 'price_discount']\n",
    "\n",
    "## Categorical features imputer\n",
    "categorical_feature_imputer = SimpleImputer(strategy='most_frequent')\n",
    "categorical_columns = ['payment_method_id', 'payment_plan_days', 'is_auto_renew', 'is_cancel', 'city', 'registered_via']\n",
    "\n",
    "## Constant imputer\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value='not_specified')\n",
    "constant_impute_column = ['gender']\n",
    "constant_imputer_pipeline = Pipeline([('imputer', constant_imputer), ('one_hot_encoder', OneHotEncoder())])\n",
    "\n",
    "## Combine all the imputation transformers with Column Transformer\n",
    "column_transformer = ColumnTransformer(transformers=[('numeric_imputer', numeric_feature_imputer, numeric_columns),\n",
    "                                                     ('categorical_imputer', categorical_feature_imputer, categorical_columns),\n",
    "                                                     ('constant_imputer', constant_imputer_pipeline, constant_impute_column)])\n",
    "\n",
    "## Final pipeline with scaling\n",
    "pipeline = Pipeline([('imputation_step', column_transformer), ('scale_data', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2826,
     "status": "ok",
     "timestamp": 1614114171798,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "U7hzaqJMv9r_",
    "outputId": "1470538d-6871-4dbe-ff4f-03cfb59e8e8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputation_step',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric_imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='median',\n",
       "                                                                verbose=0),\n",
       "                                                  ['plan_list_price',\n",
       "                                                   'actual_amount_paid', 'bd',\n",
       "                                                   'num_25', 'num_50', 'num_7...\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value='not_specified',\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('one_hot_encoder',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['gender'])],\n",
       "                                   verbose=False)),\n",
       "                ('scale_data',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lexxpT7hsFN9"
   },
   "outputs": [],
   "source": [
    "## Pre-process train data\n",
    "x_train_tot = pipeline.transform(train_df)\n",
    "y_train_tot = train_df.is_churn.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuNDR7f064uC"
   },
   "source": [
    "## Downsample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5FDG4wg7JwU"
   },
   "outputs": [],
   "source": [
    "## Downsample data with class 0 \n",
    "x_train_0 = resample(x_train_tot[y_train_tot == 0], replace=False, n_samples=int(len(x_train_tot[y_train_tot==0])*0.30), random_state=10)\n",
    "\n",
    "x_train = np.vstack((x_train_0, x_train_tot[y_train_tot == 1]))\n",
    "y_train = np.hstack((np.zeros(len(x_train_0), dtype=int), np.ones(len(x_train_tot[y_train_tot == 1]), dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQwGRpauuucz"
   },
   "outputs": [],
   "source": [
    "## This helper function explains the confusion matrix obtained from confusion_matrix method\n",
    "def confusion_matrix_report(confusion_arr:np.ndarray):\n",
    "    \"\"\"\n",
    "        Function to explain the confusion matrix \n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        confusion_arr  :   np.ndarray containing values of confusion matrix\n",
    "        \n",
    "        Returns a dictionary explaining each value in confusion_arr\n",
    "    \"\"\"\n",
    "    return {\"True Positive\": confusion_arr[1,1],\n",
    "            \"False Positive\": confusion_arr[0,1],\n",
    "            \"True Negative\": confusion_arr[0,0],\n",
    "            \"False Negative\": confusion_arr[1,0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfcYRE0ECCYn"
   },
   "source": [
    "## ML autopilot \n",
    "This ML autopilot runs as follows:\n",
    "\n",
    "* For the models specified, find the best set of parameters (from the specified list of parameters to search) using grid search and cross validation\n",
    "* For each of the models, the best performing version is stored which can be used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6v02rd5wZU7"
   },
   "outputs": [],
   "source": [
    "class MLAutopilot:\n",
    "    def __init__(self, model_name=None, model_params=None):\n",
    "        if model_name is not None and model_params is not None:\n",
    "            self.models = model_names\n",
    "            self.model_params = model_params\n",
    "        else:      \n",
    "            self.models = {'Logistic Regression': LogisticRegression(random_state=1, n_jobs=-1),\n",
    "                           'Decision Tree Classifier': DecisionTreeClassifier(random_state=3),\n",
    "                           'Random Forest Classifier': RandomForestClassifier(random_state=4, n_jobs=-1),\n",
    "                           'Gradient Tree Boosting Classifer': GradientBoostingClassifier(random_state=5),\n",
    "                           'XGBoost Classifier': xgb.XGBClassifier(random_state=6, n_jobs=-1)}\n",
    "\n",
    "            self.params = {'Logistic Regression': [{'penalty': ['l2'], 'C': [1.0, 0.5]},\n",
    "                                                   {'penalty': ['l1'], 'C': [1.0, 0.5], 'solver': ['liblinear']}],\n",
    "                           'Decision Tree Classifier': {'criterion': ['gini', 'entropy'], 'min_samples_split': [2,5,10,25,50], 'min_samples_leaf': [1, 5, 10, 25]},\n",
    "                           'Random Forest Classifier': {'n_estimators': [100, 250, 500, 1000], 'criterion': ['gini', 'entropy'], 'min_samples_split': [2,5,10,25,50], \n",
    "                                                        'min_samples_leaf': [1, 5, 10, 25]},\n",
    "                           'Gradient Tree Boosting Classifer': {'loss': ['deviance', 'exponential'], 'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
    "                                                                'n_estimators': [100, 200, 500, 1000], 'subsample': [1.0, 0.8, 0.6, 0.4], 'max_depth': [3, 5, 10]},\n",
    "                           'XGBoost Classifier': {'n_estimators': [100, 500, 1000], 'max_depth': [3, 5, 10], 'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "                                                  'subsample': [0.6, 0.8, 1.0]}}\n",
    "          \n",
    "\n",
    "        self.models_grid_search = {}\n",
    "        self.models_best_model = {}\n",
    "        self.models_cv_score = {}\n",
    "        self.baseline_models_score = {}\n",
    "\n",
    "    \n",
    "    def run_baseline_model(self, x_train: np.ndarray, y_train: np.ndarray, scoring_metric: str = 'f1', cv: int = 5):\n",
    "        \"\"\"\n",
    "            Method to create baseline model for each of the individual model.\n",
    "            Runs the models with default parameters\n",
    "        \"\"\"        \n",
    "        print(\"Running baseline\")\n",
    "        print(f\"Evaluation metric: {scoring_metric}\")\n",
    "        for n, model in enumerate(self.models.items()):\n",
    "            ## Fit baseline model\n",
    "            self.baseline_models_score[model[0]] = cross_val_score(model[1], x_train, y_train, cv=cv, scoring=scoring_metric)\n",
    "\n",
    "            ## Score predictions\n",
    "            #self.baseline_models_score[model[0]] = eval(scoring_metric)(y_train, model[1].predict(x_train))\n",
    "\n",
    "        print(\"Ran baseline model(s)\") \n",
    "\n",
    "\n",
    "    def run_automl(self, x_train: np.ndarray, y_train: np.ndarray, scoring_metric: str = 'f1', cv: int = 5, param_search_type: str = 'grid'):\n",
    "        \"\"\"\n",
    "            Method to run AutoML\n",
    "        \"\"\"\n",
    "        print(f\"Evaluation metric: {scoring_metric}\")\n",
    "        print(f\"Number of models to run: {len(self.models)}\")\n",
    "        for n, model in enumerate(self.models.items()):\n",
    "            print(f\"Running {model[0]} model\")\n",
    "            mod_time = time.time()\n",
    "            \n",
    "            if param_search_type == 'grid':\n",
    "                # Perform Grid Search\n",
    "                self.models_grid_search[model[0]] = GridSearchCV(estimator=self.models[model[0]], param_grid=self.params[model[0]], \n",
    "                                                                       scoring=scoring_metric, cv=cv)\n",
    "            elif param_search_type == 'random':\n",
    "                # Perform Randomized Grid Search\n",
    "                self.models_grid_search[model[0]] = RandomizedSearchCV(estimator=self.models[model[0]], param_distributions=self.params[model[0]], \n",
    "                                                                       scoring=scoring_metric, cv=cv)\n",
    "            else:\n",
    "                raise TypeError(\"Parameter Search type must be either grid or random\")\n",
    "            \n",
    "            self.models_grid_search[model[0]].fit(x_train, y_train)\n",
    "            \n",
    "            # Store best estimator based on Grid CV search\n",
    "            self.models_best_model[model[0]] = self.models_grid_search[model[0]].best_estimator_\n",
    "            \n",
    "            # Store CV score based on average CV score of the best model\n",
    "            self.models_cv_score[model[0]] = self.models_grid_search[model[0]].best_score_\n",
    "\n",
    "            print(f\"Model run time: {round(time.time() - mod_time, 2)} seconds\")\n",
    "            print(f\"CV score: {round(self.models_cv_score[model[0]], 4)}\")\n",
    "\n",
    "    \n",
    "    def get_prediction(self, pred_data:np.ndarray, model_name:str, loaded_model: bool = True):\n",
    "        \"\"\"\n",
    "            Method to get prediction from trained model\n",
    "        \"\"\"\n",
    "        if not isinstance(model_name, str) or not isinstance(pred_data, np.ndarray):\n",
    "            raise AssertionError(\"Model name must be a string and pred_data must be a numpy.ndarray\")\n",
    "\n",
    "        ## Compute and return the predictions with the best model for model_name\n",
    "        if loaded_model:\n",
    "            return self.loaded_models[model_name].predict(pred_data)\n",
    "        else:\n",
    "            return self.models_best_model[model_name].predict(pred_data)\n",
    "\n",
    "\n",
    "    def get_score(self, pred_data:np.ndarray, truth_label:np.ndarray, model_name:str, metric:str, loaded_model: bool = True):\n",
    "        \"\"\"\n",
    "            Get scores for an input dataset\n",
    "        \"\"\"\n",
    "        if not isinstance(model_name, str) or not isinstance(metric, str) or not isinstance(pred_data, np.ndarray) or not isinstance(truth_label, np.ndarray):\n",
    "            raise AssertionError(\"Model name and metric must be a string, and pred_data and truth_label must be a numpy.ndarray\")\n",
    "        \n",
    "        ## Step 1: Compute predictions\n",
    "        if loaded_model:\n",
    "            predictions = self.loaded_models[model_name].predict(pred_data)\n",
    "        else:\n",
    "            predictions = self.models_best_model[model_name].predict(pred_data)\n",
    "\n",
    "        ## Step 2: Compute metric\n",
    "        return eval(metric)(truth_label, predictions)\n",
    "                        \n",
    "                  \n",
    "    def save_model(self, model_name: str, save_loc: str=None):\n",
    "        \"\"\"\n",
    "            Method to save ML model\n",
    "\n",
    "            Parameters\n",
    "            -----------\n",
    "            model_name  :  str containing name of the model to save\n",
    "            save_loc    :  str containing location to save model\n",
    "\n",
    "            Returns a string if model has been saved successfully\n",
    "        \"\"\"\n",
    "        if save_loc is None:\n",
    "            Path.cwd().joinpath('saved_model').mkdir(parents=True, exist_ok=True)\n",
    "            save_loc = Path.cwd().joinpath('saved_model', model_name+'.pkl')\n",
    "\n",
    "        try:\n",
    "            joblib.dump(self.models_best_model[model_name], save_loc)\n",
    "        except:\n",
    "            raise IOError(\"Could not save the model. Check model name and file path\")\n",
    "        else:\n",
    "            print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "    def load_trained_model(self, model_names_list: list, folder_path):\n",
    "        \"\"\"\n",
    "            Method to load trained model\n",
    "        \"\"\"  \n",
    "        self.loaded_models = dict()\n",
    "        for model_name in model_names_list:\n",
    "            saved_location = folder_path.parent.joinpath('saved_models', model_name+'.pkl')\n",
    "            self.loaded_models[model_name] = joblib.load(saved_location)\n",
    "        print(\"Models loaded successfully!\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443549,
     "status": "ok",
     "timestamp": 1614114879810,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "qiZOd0C0bHoN",
    "outputId": "913e8e40-04f1-4802-9e3d-17b24c0f88a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline\n",
      "Evaluation metric: f1\n",
      "Ran baseline model(s)\n"
     ]
    }
   ],
   "source": [
    "## Run baseline\n",
    "ml_autopilot = MLAutopilot()\n",
    "ml_autopilot.run_baseline_model(x_train, y_train, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659557,
     "status": "ok",
     "timestamp": 1613889572273,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "bXs0n3TY2-32",
    "outputId": "a125a564-92c3-4357-f818-11b1e2304e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score\n",
      "{'Logistic Regression': 0.5682422281544017, 'Decision Tree Classifier': 0.7139742848863072, 'Random Forest Classifier': 0.7961368493893011, 'Gradient Tree Boosting Classifer': 0.7919385123672495, 'XGBoost Classifier': 0.7912586696953416}\n",
      "CV score standard deviation\n",
      "{'Logistic Regression': 0.003962611016560652, 'Decision Tree Classifier': 0.003173705737890884, 'Random Forest Classifier': 0.005119508322991693, 'Gradient Tree Boosting Classifer': 0.005055227023122885, 'XGBoost Classifier': 0.004925448478666706}\n"
     ]
    }
   ],
   "source": [
    "## Baseline score\n",
    "print(\"Mean CV score\")\n",
    "print({k:np.mean(v) for k, v in ml_autopilot.baseline_models_score.items()})\n",
    "print(\"CV score standard deviation\")\n",
    "print({k:np.std(v) for k, v in ml_autopilot.baseline_models_score.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsU2ecupYxN7",
    "outputId": "7f855271-d0ae-40e9-878e-1a28b1e42181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: f1\n",
      "Number of models to run: 5\n",
      "Running Logistic Regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model run time: 130.68 seconds\n",
      "CV score: 0.5683\n",
      "Running Decision Tree Classifier model\n",
      "Model run time: 179.28 seconds\n",
      "CV score: 0.7917\n",
      "Running Random Forest Classifier model\n",
      "Model run time: 10840.27 seconds\n",
      "CV score: 0.7992\n",
      "Running Gradient Tree Boosting Classifer model\n",
      "Model run time: 17465.11 seconds\n",
      "CV score: 0.7985\n",
      "Running XGBoost Classifier model\n"
     ]
    }
   ],
   "source": [
    "## Run ML pipeline (Takes about a day to run all the models)\n",
    "#ml_autopilot = MLAutopilot()\n",
    "ml_autopilot.run_automl(x_train, y_train, 'f1', 5, 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4003,
     "status": "ok",
     "timestamp": 1613952241132,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "mStfD-i5HV7u",
    "outputId": "96d50dbb-e35d-4d70-a505-04e9c16156ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Model saved successfully!\n",
      "Model saved successfully!\n",
      "Model saved successfully!\n",
      "Model saved successfully!\n",
      "Models saved!\n"
     ]
    }
   ],
   "source": [
    "## Save trained models\n",
    "for model_name in ml_autopilot.models_best_model:\n",
    "    save_location = folder_path.parent.joinpath('saved_models', model_name+'.pkl')\n",
    "    ml_autopilot.save_model(model_name, save_location)\n",
    "print(\"Models saved!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYGiNE1mJMFr"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpAZeg8RJLE1"
   },
   "outputs": [],
   "source": [
    "# ## Load saved models\n",
    "# model_names_list = ['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier', 'Gradient Tree Boosting Classifer', 'XGBoost Classifier']\n",
    "# trained_models = dict()\n",
    "# for model_name in model_names_list:\n",
    "#     saved_location = folder_path.parent.joinpath('saved_models', model_name+'.pkl')\n",
    "#     trained_models[model_name] = joblib.load(saved_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nghEhuHcL57u"
   },
   "outputs": [],
   "source": [
    "## Load saved models\n",
    "model_names_list = ['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier', 'Gradient Tree Boosting Classifer', 'XGBoost Classifier']\n",
    "#ml_autopilot = MLAutopilot()\n",
    "ml_autopilot.load_trained_model(model_names_list, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OvG64aaTbaC"
   },
   "outputs": [],
   "source": [
    "## Preprocess validation data\n",
    "x_val = pipeline.transform(val_df)\n",
    "y_val = val_df.is_churn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44979,
     "status": "ok",
     "timestamp": 1611984965801,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "pvhRl3JyTCUf",
    "outputId": "27db96f0-7fd1-4f13-a882-4e82cdf88100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: f1_score\n",
      "Model name: Logistic Regression\n",
      "f1_score : 0.5298\n",
      "Model name: Decision Tree Classifier\n",
      "f1_score : 0.7149\n",
      "Model name: Random Forest Classifier\n",
      "f1_score : 0.746\n",
      "Model name: Gradient Tree Boosting Classifer\n",
      "f1_score : 0.7449\n",
      "Model name: XGBoost Classifier\n",
      "f1_score : 0.7449\n"
     ]
    }
   ],
   "source": [
    "## Validate on all models\n",
    "eval_metric = 'f1_score'\n",
    "print(f\"Evaluation metric: {eval_metric}\")\n",
    "for model in model_names_list:\n",
    "    print(f\"Model name: {model}\")\n",
    "    print(f\"{eval_metric} : {round(ml_autopilot.get_score(x_val, y_val, model, eval_metric), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44844,
     "status": "ok",
     "timestamp": 1611985061265,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "kaZ-oRQcyeCt",
    "outputId": "27781500-ffb5-4631-9e3a-178085e0d7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: roc_auc_score\n",
      "Model name: Logistic Regression\n",
      "roc_auc_score : 0.7007\n",
      "Model name: Decision Tree Classifier\n",
      "roc_auc_score : 0.8404\n",
      "Model name: Random Forest Classifier\n",
      "roc_auc_score : 0.8414\n",
      "Model name: Gradient Tree Boosting Classifer\n",
      "roc_auc_score : 0.8404\n",
      "Model name: XGBoost Classifier\n",
      "roc_auc_score : 0.8407\n"
     ]
    }
   ],
   "source": [
    "## Validate on all models\n",
    "eval_metric = 'roc_auc_score'\n",
    "print(f\"Evaluation metric: {eval_metric}\")\n",
    "for model in model_names_list:\n",
    "    print(f\"Model name: {model}\")\n",
    "    print(f\"{eval_metric} : {round(ml_autopilot.get_score(x_val, y_val, model, eval_metric), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45483,
     "status": "ok",
     "timestamp": 1611986485705,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "nTdp-Ksp1aMZ",
    "outputId": "7cc37395-61e1-459f-f4e8-1bfb1f335b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: confusion_matrix\n",
      "Model name: Logistic Regression\n",
      "confusion_matrix : {'True Positive': 4838, 'False Positive': 1810, 'True Negative': 117655, 'False Negative': 6777}\n",
      "Model name: Decision Tree Classifier\n",
      "confusion_matrix : {'True Positive': 8214, 'False Positive': 3150, 'True Negative': 116315, 'False Negative': 3401}\n",
      "Model name: Random Forest Classifier\n",
      "confusion_matrix : {'True Positive': 8129, 'False Positive': 2049, 'True Negative': 117416, 'False Negative': 3486}\n",
      "Model name: Gradient Tree Boosting Classifer\n",
      "confusion_matrix : {'True Positive': 8105, 'False Positive': 2041, 'True Negative': 117424, 'False Negative': 3510}\n",
      "Model name: XGBoost Classifier\n",
      "confusion_matrix : {'True Positive': 8114, 'False Positive': 2057, 'True Negative': 117408, 'False Negative': 3501}\n"
     ]
    }
   ],
   "source": [
    "## Validate on all models\n",
    "eval_metric = 'confusion_matrix'\n",
    "print(f\"Evaluation metric: {eval_metric}\")\n",
    "for model in model_names_list:\n",
    "    print(f\"Model name: {model}\")\n",
    "    print(f\"{eval_metric} : {confusion_matrix_report(ml_autopilot.get_score(x_val, y_val, model, eval_metric))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76580,
     "status": "ok",
     "timestamp": 1611986531993,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "bhL1jvQN3erm",
    "outputId": "68ad49eb-ae31-4baa-880d-7bfbd4860ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: classification_report\n",
      "Model name: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    119465\n",
      "           1       0.73      0.42      0.53     11615\n",
      "\n",
      "    accuracy                           0.93    131080\n",
      "   macro avg       0.84      0.70      0.75    131080\n",
      "weighted avg       0.93      0.93      0.93    131080\n",
      "\n",
      "Model name: Decision Tree Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97    119465\n",
      "           1       0.72      0.71      0.71     11615\n",
      "\n",
      "    accuracy                           0.95    131080\n",
      "   macro avg       0.85      0.84      0.84    131080\n",
      "weighted avg       0.95      0.95      0.95    131080\n",
      "\n",
      "Model name: Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    119465\n",
      "           1       0.80      0.70      0.75     11615\n",
      "\n",
      "    accuracy                           0.96    131080\n",
      "   macro avg       0.88      0.84      0.86    131080\n",
      "weighted avg       0.96      0.96      0.96    131080\n",
      "\n",
      "Model name: Gradient Tree Boosting Classifer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    119465\n",
      "           1       0.80      0.70      0.74     11615\n",
      "\n",
      "    accuracy                           0.96    131080\n",
      "   macro avg       0.88      0.84      0.86    131080\n",
      "weighted avg       0.96      0.96      0.96    131080\n",
      "\n",
      "Model name: XGBoost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    119465\n",
      "           1       0.80      0.70      0.74     11615\n",
      "\n",
      "    accuracy                           0.96    131080\n",
      "   macro avg       0.88      0.84      0.86    131080\n",
      "weighted avg       0.96      0.96      0.96    131080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Validate on all models\n",
    "eval_metric = 'classification_report'\n",
    "print(f\"Evaluation metric: {eval_metric}\")\n",
    "for model in model_names_list:\n",
    "    print(f\"Model name: {model}\")\n",
    "    print(ml_autopilot.get_score(x_val, y_val, model, eval_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxRzH7zS5MJy"
   },
   "source": [
    "From the model evaluation on validation set, select\n",
    "1. Random Forest model (due to its robustness compared to a single decision tree)\n",
    "2. XGBoost model (due to it being faster than Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-LcGK3b7xm0"
   },
   "outputs": [],
   "source": [
    "selected_models = ['Random Forest Classifier', 'XGBoost Classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjS6Hz6_5kmz"
   },
   "source": [
    "Next steps:\n",
    "1. Test the selected models on test set\n",
    "2. Model interpretation\n",
    "3. Evaluate on an use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx4en1Nc7gb8"
   },
   "source": [
    "## Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XU2jQUC244bu"
   },
   "outputs": [],
   "source": [
    "## Preprocess test data\n",
    "x_test = pipeline.transform(test_data)\n",
    "y_test = test_data.is_churn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28628,
     "status": "ok",
     "timestamp": 1611987591119,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "nY2WfR2F7qHO",
    "outputId": "aa400c33-b006-491d-d718-0928a0d1d7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: f1_score\n",
      "Model name: Random Forest Classifier\n",
      "0.7513\n",
      "Model name: XGBoost Classifier\n",
      "0.7508\n"
     ]
    }
   ],
   "source": [
    "## Test on the selected models\n",
    "eval_metric = 'f1_score'\n",
    "print(f\"Evaluation metric: {eval_metric}\")\n",
    "for model in selected_models:\n",
    "    print(f\"Model name: {model}\")\n",
    "    print(round(ml_autopilot.get_score(x_test, y_test, model, eval_metric), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28442,
     "status": "ok",
     "timestamp": 1611987668287,
     "user": {
      "displayName": "nithish kaviyan",
      "photoUrl": "",
      "userId": "13914560553667250358"
     },
     "user_tz": 300
    },
    "id": "bFYYpNtA8i-a",
    "outputId": "c0eca664-3b16-4b35-ae44-cf375ca416b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metric: roc_auc_score\n",
      "Model name: Random Forest Classifier\n",
      "0.8433\n",
      "Model name: XGBoost Classifier\n",
      "0.8429\n"
     ]
    }
   ],
   "source": [
    "## Test on the selected models\n",
    "eval_metric = 'roc_auc_score'\n",
    "print(f\"Evaluation metric: {eval_metric}\")\n",
    "for model in selected_models:\n",
    "    print(f\"Model name: {model}\")\n",
    "    print(round(ml_autopilot.get_score(x_test, y_test, model, eval_metric), 4))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNM/gFfOR6yEnDOPLD/wh5A",
   "collapsed_sections": [
    "Sx4en1Nc7gb8"
   ],
   "name": "churn_modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
